{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The approach is inspired by this post:\n",
    "# https://www.kaggle.com/code/wpncrh/doc2vec-and-logistic-regression/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d42f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/martin/miniconda3/envs/baka/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/martin/miniconda3/envs/baka/lib/python3.7/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/martin/miniconda3/envs/baka/lib/python3.7/site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/martin/miniconda3/envs/baka/lib/python3.7/site-packages (from gensim) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "298ceec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e51fb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmas = pd.read_csv('/home/martin/ML/ML-2022-T28-P05/preprocessed_text/lemmas.csv')\n",
    "# For some reason the above method truncated the lemmas list\n",
    "text_lemmas = dict()\n",
    "with open('/home/martin/ML/ML-2022-T28-P05/preprocessed_text/lemmas.csv', mode ='r')as file:\n",
    "    lemmas_file = csv.reader(file)\n",
    "    for index, line in enumerate(lemmas_file):\n",
    "        if index != 0:\n",
    "            text_lemmas[line[0]] = eval(line[1])\n",
    "\n",
    "train_ids = pd.read_csv('/home/martin/ML/ML-2022-T28-P05/original_data/train.csv')\n",
    "test_ids = pd.read_csv('/home/martin/ML/ML-2022-T28-P05/original_data/test.csv')\n",
    "skills_df = pd.read_csv('/home/martin/ML/ML-2022-T28-P05/original_data/skills.csv')\n",
    "skill_list = skills_df['skill_id'].tolist()\n",
    "test_all = pd.read_csv('/home/martin/ML/ML-2022-T28-P05/data/test_texts_with_ids.csv', sep = \"|\", encoding = \"UTF-8\")\n",
    "test_X = test_all[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab85c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining train set lemmas and skill names to one list\n",
    "lemmas_with_skills = []\n",
    "trainlist = train_ids.values.tolist()\n",
    "for row in trainlist:\n",
    "    text_id = row[0]\n",
    "    text_skills = row[1].split(\" \")\n",
    "    #lemmas_with_skills.append([text_lemmas[text_id], text_skills])\n",
    "    lemmas_with_skills.append([[lemma.lower() for lemma in text_lemmas[text_id]], text_skills]) # Lowercasing\n",
    "\n",
    "    \n",
    "# Making that a dataframe\n",
    "train = pd.DataFrame (lemmas_with_skills, columns = ['lemmas', 'skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c97e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmas</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[kontrollima, töö, ja, mõõteriist, ning, isiku...</td>\n",
       "      <td>[s6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mõõtmine]</td>\n",
       "      <td>[s19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[meeskonnaliige, arendama, oma, teadmine, järg...</td>\n",
       "      <td>[s15, s20, s42, s48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[samas, ei, kaduma, ikt-oskus, kõrval, vajadus...</td>\n",
       "      <td>[s13, s9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[kasutama, oma, igapäevatöö, arvuti, infotöötl...</td>\n",
       "      <td>[s0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lemmas                 skill\n",
       "0  [kontrollima, töö, ja, mõõteriist, ning, isiku...                  [s6]\n",
       "1                                         [mõõtmine]                 [s19]\n",
       "2  [meeskonnaliige, arendama, oma, teadmine, järg...  [s15, s20, s42, s48]\n",
       "3  [samas, ei, kaduma, ikt-oskus, kõrval, vajadus...             [s13, s9]\n",
       "4  [kasutama, oma, igapäevatöö, arvuti, infotöötl...                  [s0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4ef39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining test set lemmas and text ids to one list\n",
    "lemmas_with_skills = [[text_id, text_lemmas[text_id]] for text_id in test_ids['text_id'].tolist()]\n",
    "\n",
    "#for text_id in test_ids['text_id'].tolist():\n",
    "#    lowercased [lemma.lower() for lemma in text_lemmas[text_id]]\n",
    "    \n",
    "# Making that a dataframe\n",
    "test = pd.DataFrame (lemmas_with_skills, columns = ['text_id', 'lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "346da76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text0</td>\n",
       "      <td>[võistlusülesanne, lahendamine, vajalik, erial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text106</td>\n",
       "      <td>[tegemine, olema, inimene, ,, kes, olema, avat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text108</td>\n",
       "      <td>[72%, juht, tooma, kõige, tähtsam, tegur, välj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text109</td>\n",
       "      <td>[sagedane, muutus, tööelu, tähendama, ka, valm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text112</td>\n",
       "      <td>[palju, olema, jutt, see, ,, et, eestlane, ole...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                             lemmas\n",
       "0    text0  [võistlusülesanne, lahendamine, vajalik, erial...\n",
       "1  text106  [tegemine, olema, inimene, ,, kes, olema, avat...\n",
       "2  text108  [72%, juht, tooma, kõige, tähtsam, tegur, välj...\n",
       "3  text109  [sagedane, muutus, tööelu, tähendama, ka, valm...\n",
       "4  text112  [palju, olema, jutt, see, ,, et, eestlane, ole..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a225e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for index, row in train_ids.iterrows():    \n",
    "    text_id = row['text_id']\n",
    "    documents.append(TaggedDocument(text_lemmas[text_id], row['skills'].split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1c01f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(vector_size=100, window=8, min_count=1, workers=4, epochs=15)\n",
    "doc2vec_model.build_vocab(documents)\n",
    "doc2vec_model.train(documents, total_examples=len(documents), epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f6ed46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferred test set\n",
    "test_X = [doc2vec_model.infer_vector(lemmas) for lemmas in test['lemmas'].tolist()]\n",
    "\n",
    "# Inferred train set\n",
    "documents = dict\n",
    "\n",
    "# Skills column into 50 one-hot vectors\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "mlb = MultiLabelBinarizer()\n",
    "text_skills_df = train.join(pd.DataFrame(mlb.fit_transform(train.pop('skill')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=train.index))\n",
    "\n",
    "train_X = [doc2vec_model.infer_vector(lemmas) for lemmas in train['lemmas'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41083ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = dict()\n",
    "test_preds_scores = dict()\n",
    "\n",
    "for skill in skill_list:\n",
    "    #print(\"Class =\", skill)\n",
    "    train_y = text_skills_df[skill]\n",
    "\n",
    "    total = len(train_y)\n",
    "    pos = train_y.value_counts()[1]\n",
    "    neg = train_y.value_counts()[0]\n",
    "\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    \n",
    "    lin = LinearRegression()\n",
    "    lin.fit(train_X, train_y)\n",
    "    \n",
    "    test_preds[skill] = lin.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49757e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_preds = pd.DataFrame.from_dict(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e02d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = skills_preds.apply(lambda x: x.index[x>=0.5].tolist(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62c83fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = [['text_id','skills']]\n",
    "predictions = df.tolist()\n",
    "for i in range(len(df)):\n",
    "    labels = predictions[i]\n",
    "    text_id = [test_ids['text_id'].tolist()[i]]\n",
    "    if len(labels) == 0:\n",
    "        labels.append('s0')\n",
    "    labels_string = ' '.join(labels)\n",
    "    submission.append([text_id[0], labels_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3e4d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('/home/martin/ML/ML-2022-T28-P05/submissions/Doc2Vec_LinearRegression_s0.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerows(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532a454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
